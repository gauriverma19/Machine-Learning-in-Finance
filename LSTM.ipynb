{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6fNvTBUDYuJVGNGzQasA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauriverma19/Machine-Learning-in-Finance/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACkX-0erihJa"
      },
      "source": [
        "# **LSTM FOR BMY STOCK PREDICTION**\n",
        "\n",
        "We will train a Recurrent Neural Network (LSTM). We will use one of the deep learning libraries, Keras, to build the neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J48WASXwPenY"
      },
      "source": [
        "Long Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. They were introduced by Hochreiter & Schmidhuber (1997), and were refined and popularized by many people in following work.1 They work tremendously well on a large variety of problems, and are now widely used.\n",
        "\n",
        "LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!\n",
        "\n",
        "All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heK-Mku1aynw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "d02d752d-0447-419d-927d-4bcb90cc38b5"
      },
      "source": [
        "#importing necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import pandas_datareader.data as web\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#reading web data\n",
        "start = datetime.datetime(2016, 1, 1)\n",
        "end = datetime.datetime(2020, 7, 31)\n",
        "\n",
        "df = web.DataReader(\"BMY\", 'yahoo', start, end)\n",
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-07-27</th>\n",
              "      <td>58.619999</td>\n",
              "      <td>57.349998</td>\n",
              "      <td>57.549999</td>\n",
              "      <td>58.049999</td>\n",
              "      <td>12372000.0</td>\n",
              "      <td>57.616718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-28</th>\n",
              "      <td>59.820000</td>\n",
              "      <td>58.240002</td>\n",
              "      <td>58.549999</td>\n",
              "      <td>59.430000</td>\n",
              "      <td>9816300.0</td>\n",
              "      <td>58.986420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-29</th>\n",
              "      <td>59.400002</td>\n",
              "      <td>58.590000</td>\n",
              "      <td>59.160000</td>\n",
              "      <td>59.150002</td>\n",
              "      <td>7357900.0</td>\n",
              "      <td>58.708511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-30</th>\n",
              "      <td>59.150002</td>\n",
              "      <td>58.340000</td>\n",
              "      <td>58.799999</td>\n",
              "      <td>58.869999</td>\n",
              "      <td>7175200.0</td>\n",
              "      <td>58.430595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-07-31</th>\n",
              "      <td>59.090000</td>\n",
              "      <td>57.770000</td>\n",
              "      <td>58.880001</td>\n",
              "      <td>58.660000</td>\n",
              "      <td>10443000.0</td>\n",
              "      <td>58.222164</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 High        Low       Open      Close      Volume  Adj Close\n",
              "Date                                                                         \n",
              "2020-07-27  58.619999  57.349998  57.549999  58.049999  12372000.0  57.616718\n",
              "2020-07-28  59.820000  58.240002  58.549999  59.430000   9816300.0  58.986420\n",
              "2020-07-29  59.400002  58.590000  59.160000  59.150002   7357900.0  58.708511\n",
              "2020-07-30  59.150002  58.340000  58.799999  58.869999   7175200.0  58.430595\n",
              "2020-07-31  59.090000  57.770000  58.880001  58.660000  10443000.0  58.222164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci54d3y3a9Aq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebd6e6e-b43a-47a4-aff5-5ff72c9b07dd"
      },
      "source": [
        "#training the data\n",
        "training_set = df.iloc[:,1:2].values\n",
        "\n",
        "print(training_set)\n",
        "print(\"********************\")\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[66.37999725]\n",
            " [67.41999817]\n",
            " [66.84999847]\n",
            " ...\n",
            " [58.59000015]\n",
            " [58.34000015]\n",
            " [57.77000046]]\n",
            "********************\n",
            "(1153, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytzGmOYQi_hZ"
      },
      "source": [
        "# Feature scaling\n",
        "The performance of the neural network will be better if the entire training input is in the same range. As we can see from above the stock prices are not in the same range. So, we need to scale the training data such that they are in the same range. This process is called Feature Scaling. The two popular methods for feature scaling are:\n",
        "\n",
        "Standardization\n",
        "$ x' = \\frac{x - \\bar{x}}{\\sigma} $\n",
        "\n",
        "where $ x $ is the original feature vector, $ \\bar{x} $ is the mean of that feature vector, and $ \\sigma $ is its standard deviation.\n",
        "\n",
        "Normalization (Min-Max normalization)\n",
        "$ x' = \\frac{x - \\text{min}(x)}{\\text{max}(x)-\\text{min}(x)} $\n",
        "\n",
        "where $ x $ is an original value, $ x' $ is the normalized value.\n",
        "\n",
        "It is recommended to use Normalization in the case of RNN networks. Therefore we use Min-Max normalization here. You may also experiment with different feature scaling methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxbgTVSabcqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821e879c-79ee-4691-ec7a-7dbff6788253"
      },
      "source": [
        "#implementing feature scaling\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range = (0,1)) \n",
        "scaled_training_set = scaler.fit_transform(training_set)\n",
        "\n",
        "scaled_training_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.70689136],\n",
              "       [0.73765151],\n",
              "       [0.7207926 ],\n",
              "       ...,\n",
              "       [0.47648625],\n",
              "       [0.46909198],\n",
              "       [0.45223308]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxt29uNobf_S"
      },
      "source": [
        "#scaled training sets\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60,1153):#1258\n",
        "    X_train.append(scaled_training_set[i-60:i, 0])\n",
        "    y_train.append(scaled_training_set[i, 0])\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvPy0vqzbyZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eacf1e1-f67e-4e39-dc7c-845b0eb6c804"
      },
      "source": [
        "#shape of training data\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1093, 60)\n",
            "(1093,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JG9dFJajGzL"
      },
      "source": [
        "# Reshaping:\n",
        "\n",
        "The input shape of the LSTM is 3D tensor with shape (batch_size, timesteps, input_dim). Batch_size represents the number of iterations required to traverse through the entire training data. Timesteps represent the number of inputs required for each prediction. In our scenario it is 60."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUianZucb13n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f8a94f-9abe-40fa-d610-813199e4e701"
      },
      "source": [
        "#reshaping the training data\n",
        "\n",
        "X_train = np.reshape(X_train,(X_train.shape[0], X_train.shape[1], 1))\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1093, 60, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U101DmsjjQIg"
      },
      "source": [
        "# **Building the Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajie3XaUb5ea"
      },
      "source": [
        "#importing libraries for building the neural netowkr using Keras sequential layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzFPoGlMb8HO"
      },
      "source": [
        "#--------------------------------------------#\n",
        "#  Initialization and Adding layers to RNN   #\n",
        "#--------------------------------------------#\n",
        "regressor = Sequential()\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences= True, input_shape = (X_train.shape[1], 1)))   # the first LSTM layer\n",
        "regressor.add(Dropout(0.2))                     \n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences= True))  # the second LSTM layer\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences= True))  # the third LSTM layer\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(LSTM(units = 50))  # the fourth LSTM layer\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(Dense(units=1))   # the dense layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KNyuW4lb-ZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27821de9-0b0f-4f59-9b09-f0c3ec754a09"
      },
      "source": [
        "#-----------------------------------------------------#\n",
        "#  Compiling and Fitting the RNN to the Training set  #\n",
        "#-----------------------------------------------------#\n",
        "\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error') \n",
        "regressor.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "# the loss function \"mean_squared_error\"(MSE) is used because it is a Regression problem.\n",
        "# epochs = no of iterations. After every 32 (batch_size) datasets, the MSE will be calculated and \n",
        "# the tweaks will be Back Propagated i.e., the weights will be tweaked for every 32 training datasets."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - 3s 88ms/step - loss: 0.0417\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.0133\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.0116\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - 3s 95ms/step - loss: 0.0102\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0090\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.0091\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0087\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - 3s 98ms/step - loss: 0.0073\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0065\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0077\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0064\n",
            "Epoch 12/100\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.0058\n",
            "Epoch 13/100\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.0059\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.0056\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0053\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0055\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0049\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0051\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.0048\n",
            "Epoch 20/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0046\n",
            "Epoch 21/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0047\n",
            "Epoch 22/100\n",
            "35/35 [==============================] - 3s 100ms/step - loss: 0.0045\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0048\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0050\n",
            "Epoch 25/100\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.0041\n",
            "Epoch 26/100\n",
            "35/35 [==============================] - 4s 107ms/step - loss: 0.0047\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0038\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0038\n",
            "Epoch 29/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0035\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - 3s 100ms/step - loss: 0.0039\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0037\n",
            "Epoch 32/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0034\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0033\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0034\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0035\n",
            "Epoch 36/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0033\n",
            "Epoch 37/100\n",
            "35/35 [==============================] - 3s 100ms/step - loss: 0.0032\n",
            "Epoch 38/100\n",
            "35/35 [==============================] - 3s 99ms/step - loss: 0.0031\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0029\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0033\n",
            "Epoch 41/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0028\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - 3s 100ms/step - loss: 0.0031\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0030\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0031\n",
            "Epoch 45/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0027\n",
            "Epoch 46/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0026\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - 3s 100ms/step - loss: 0.0029\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0030\n",
            "Epoch 49/100\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.0026\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0032\n",
            "Epoch 51/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0029\n",
            "Epoch 52/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0026\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0026\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - 4s 100ms/step - loss: 0.0023\n",
            "Epoch 55/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0027\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - 3s 100ms/step - loss: 0.0024\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0026\n",
            "Epoch 58/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0024\n",
            "Epoch 59/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0033\n",
            "Epoch 60/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0023\n",
            "Epoch 61/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0024\n",
            "Epoch 62/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0027\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.0022\n",
            "Epoch 64/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0024\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0024\n",
            "Epoch 66/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0020\n",
            "Epoch 67/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0020\n",
            "Epoch 68/100\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.0021\n",
            "Epoch 69/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0022\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0022\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.0020\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.0019\n",
            "Epoch 73/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 74/100\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.0034\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0019\n",
            "Epoch 76/100\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.0021\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - 4s 104ms/step - loss: 0.0018\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0020\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0020\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.0022\n",
            "Epoch 81/100\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.0020\n",
            "Epoch 82/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0017\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.0018\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0020\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0021\n",
            "Epoch 87/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0017\n",
            "Epoch 88/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0017\n",
            "Epoch 89/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0019\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - 4s 101ms/step - loss: 0.0018\n",
            "Epoch 91/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0022\n",
            "Epoch 92/100\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.0017\n",
            "Epoch 93/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0017\n",
            "Epoch 94/100\n",
            "35/35 [==============================] - 4s 103ms/step - loss: 0.0021\n",
            "Epoch 95/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0019\n",
            "Epoch 96/100\n",
            "35/35 [==============================] - 4s 102ms/step - loss: 0.0018\n",
            "Epoch 97/100\n",
            "35/35 [==============================] - 4s 106ms/step - loss: 0.0018\n",
            "Epoch 98/100\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.0017\n",
            "Epoch 99/100\n",
            "35/35 [==============================] - 4s 109ms/step - loss: 0.0020\n",
            "Epoch 100/100\n",
            "35/35 [==============================] - 4s 105ms/step - loss: 0.0018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff9e81c2cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuUDMNDwjhLZ"
      },
      "source": [
        "# **Making Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6LfajjncCV9"
      },
      "source": [
        "#end = datetime.datetime(2020, 7, 31)\n",
        "\n",
        "start = datetime.datetime(2020, 8, 1)\n",
        "end = datetime.datetime(2020, 9, 1)\n",
        "dataset_test= web.DataReader(\"BMY\", 'yahoo', start, end)\n",
        "\n",
        "actual_stock_price = dataset_test.iloc[:,1:2].values\n",
        "\n",
        "# getting the Predicted Stock Prices of August 2020\n",
        "# Step1 - preparing the input for the model\n",
        "dataset_total = pd.concat((df['Open'], dataset_test['Open']), axis = 0)    # axis 0 = vertical concatination\n",
        "inputs = dataset_total[len(dataset_total)- len(dataset_test)-60:].values   # so that we can get the base index\n",
        "\n",
        "inputs = inputs.reshape(-1,1)     # before Reshaping- (80,) after Reshaping- (80,1)\n",
        "inputs = scaler.transform(inputs) # we don't need to fit because we want to use the previously calculated min & max values.\n",
        "\n",
        "X_test = []\n",
        "for i in range(60,80):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test,(X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Step2 - prediction\n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "predicted_stock_price = scaler.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb_j5mz5jm4w"
      },
      "source": [
        "We \"tranform\" the inputs because we want to maintain the consistency w.r.t what we feed to the network. In the end we \"reverse transform\" the data for the convenience of plotting. As you can see in the next section, the actual and predicted stock prices are in the original scale and are not in the transformed state.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycO6oM3vdw5G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "a2fbbf35-141f-4905-b517-9d5070041c42"
      },
      "source": [
        "#comparing predicted prices\n",
        "\n",
        "plt.plot(actual_stock_price, color = 'red', label = 'Actual BMY Stock Price')\n",
        "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted BMY Stock Price')\n",
        "plt.title('BMY Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('BMY Stock Price')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff9e43c8cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUA-jbS-VEEa"
      },
      "source": [
        "The model can be further improved and experimented by considering the following (but not limited to):\n",
        "\n",
        "* Training the model with more data. Eg: Here we have used 5 years of stock prices but you can train the model with 10 years of data.\n",
        "* Increasing the number of timesteps.\n",
        "* Adding more LSTM layers.\n",
        "* Increasing the units in the LSTM layer.\n",
        "* Adding some other indicators. Eg: If you have the financial instinct that the stock price of some other companies might be correlated to the one of BMY, you could add this other stock price as a new indicator in the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrHuB6s5QRyc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}